{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# text = \"Here is the sentence I want embeddings for.\"\n",
    "text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "print (marked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'after', 'stealing', 'money', 'from', 'the', 'bank', 'vault', ',', 'the', 'bank', 'robber', 'was', 'seen', 'fishing', 'on', 'the', 'mississippi', 'river', 'bank', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knight',\n",
       " 'lap',\n",
       " 'survey',\n",
       " 'ma',\n",
       " '##ow',\n",
       " 'noise',\n",
       " 'billy',\n",
       " '##ium',\n",
       " 'shooting',\n",
       " 'guide',\n",
       " 'bedroom',\n",
       " 'priest',\n",
       " 'resistance',\n",
       " 'motor',\n",
       " 'homes',\n",
       " 'sounded',\n",
       " 'giant',\n",
       " '##mer',\n",
       " '150',\n",
       " 'scenes']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.vocab.keys())[5000:5020]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[CLS]', 101)\n",
      "('after', 2044)\n",
      "('stealing', 11065)\n",
      "('money', 2769)\n",
      "('from', 2013)\n",
      "('the', 1996)\n",
      "('bank', 2924)\n",
      "('vault', 11632)\n",
      "(',', 1010)\n",
      "('the', 1996)\n",
      "('bank', 2924)\n",
      "('robber', 27307)\n",
      "('was', 2001)\n",
      "('seen', 2464)\n",
      "('fishing', 5645)\n",
      "('on', 2006)\n",
      "('the', 1996)\n",
      "('mississippi', 5900)\n",
      "('river', 2314)\n",
      "('bank', 2924)\n",
      "('.', 1012)\n",
      "('[SEP]', 102)\n"
     ]
    }
   ],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "  print (tup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "segments_ids = [1] * len(tokenized_text)\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 12\n",
      "Number of batches: 1\n",
      "Number of tokens: 22\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 22\n",
      "Number of layers per token: 12\n"
     ]
    }
   ],
   "source": [
    "# Convert the hidden state embeddings into single token vectors\n",
    "\n",
    "# Holds the list of 12 layer embeddings for each token\n",
    "# Will have the shape: [# tokens, # layers, # features]\n",
    "token_embeddings = [] \n",
    "\n",
    "# For each token in the sentence...\n",
    "for token_i in range(len(tokenized_text)):\n",
    "  \n",
    "  # Holds 12 layers of hidden states for each token \n",
    "  hidden_layers = [] \n",
    "  \n",
    "  # For each of the 12 layers...\n",
    "  for layer_i in range(len(encoded_layers)):\n",
    "    \n",
    "    # Lookup the vector for `token_i` in `layer_i`\n",
    "    vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "    \n",
    "    hidden_layers.append(vec)\n",
    "    \n",
    "  token_embeddings.append(hidden_layers)\n",
    "\n",
    "# Sanity check the dimensions:\n",
    "print (\"Number of tokens in sequence:\", len(token_embeddings))\n",
    "print (\"Number of layers per token:\", len(token_embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_last_4_layers = [torch.cat((layer[-1], layer[-2], layer[-3], layer[-4]), 0) for layer in token_embeddings] # [number_of_tokens, 3072]\n",
    "\n",
    "summed_last_4_layers = [torch.sum(torch.stack(layer)[-4:], 0) for layer in token_embeddings] # [number_of_tokens, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding = torch.mean(encoded_layers[11], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Our final sentence embedding vector of shape:\"), sentence_embedding[0].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.2873e-02, -2.3461e-01, -7.9924e-02,  3.8905e-01,  8.8793e-01,\n",
       "          2.1375e-01, -7.8063e-03,  6.2694e-01, -3.2631e-02, -3.4703e-01,\n",
       "          1.2331e-01, -9.4771e-02, -7.4421e-02,  4.5523e-01, -4.7217e-01,\n",
       "          1.0344e-01,  3.4667e-01,  1.0410e-01,  5.4372e-01,  6.9113e-02,\n",
       "         -8.2880e-02,  6.7866e-02,  1.2871e-01,  2.3312e-01,  4.2933e-01,\n",
       "         -1.2449e-02, -2.1360e-01,  2.2697e-01, -1.2763e-01,  2.8080e-01,\n",
       "          5.4766e-01, -1.0080e-01,  7.5650e-02, -2.7152e-01, -1.4124e-01,\n",
       "         -4.0931e-01, -1.9237e-01, -3.9813e-02, -2.3175e-01,  3.3040e-01,\n",
       "         -3.8484e-01, -3.7469e-01, -2.4978e-01,  3.2707e-01, -9.0565e-04,\n",
       "         -4.4285e-01,  7.6833e-02, -4.4617e-02,  1.9807e-02,  7.4679e-02,\n",
       "         -3.2986e-01,  8.2114e-01, -7.6256e-01, -4.1613e-04,  8.9090e-02,\n",
       "          5.3472e-01, -3.8244e-01, -6.0184e-01, -8.3941e-02, -9.6010e-02,\n",
       "          3.7689e-01, -2.5287e-01,  4.6429e-01, -5.4761e-01, -2.1230e-02,\n",
       "          2.0828e-02,  4.8191e-01,  2.8035e-01, -3.2533e-01,  3.0219e-02,\n",
       "         -4.0340e-01,  1.9626e-01, -2.1912e-01, -3.6637e-01,  6.2737e-03,\n",
       "          4.7330e-01, -8.0409e-02, -2.9862e-02, -2.9353e-01,  2.1191e-01,\n",
       "         -2.0604e-01,  3.9470e-01, -1.4167e-01,  2.4277e-01,  1.4530e-01,\n",
       "          5.1124e-02, -1.8740e-01,  7.7009e-02, -3.3880e-02,  4.4765e-01,\n",
       "         -5.5695e-02,  1.3957e-01, -1.9834e-01, -3.4934e-02, -4.2185e-01,\n",
       "          2.1998e-01,  1.4355e-02,  9.0102e-02, -2.7612e-01,  4.6219e-01,\n",
       "          1.0327e-01, -5.5465e-01,  2.5412e-01,  4.0143e-01, -2.3760e-03,\n",
       "         -1.0714e-02,  3.4206e-01,  6.8675e-02, -2.1206e-01, -9.5972e-02,\n",
       "          1.2728e-01, -2.8885e-01,  2.1959e-01, -2.6426e-01,  2.9848e-02,\n",
       "         -1.0108e-03,  4.3754e-01, -3.0179e-01, -5.3250e-01, -1.1406e-01,\n",
       "          4.0874e-01,  2.4168e-01,  3.4493e-01,  8.7342e-01, -2.4015e-01,\n",
       "          2.1779e-01,  2.8373e-02,  1.6783e-01, -1.3983e-01, -6.2004e-01,\n",
       "          3.9955e-01,  2.8869e-02,  1.7543e-01, -1.8415e-01, -2.5643e-01,\n",
       "          2.2322e-01, -1.1652e-01, -2.4955e-01, -5.3888e-01,  2.5615e-01,\n",
       "          3.0306e-01, -3.5355e-01, -8.1194e-02,  2.9323e-01,  6.4744e-02,\n",
       "          3.9605e-01,  2.6805e-01, -2.7199e-01,  1.9049e-01,  2.2043e-01,\n",
       "          2.6581e-01,  1.7944e-01, -1.3411e-01, -2.6965e-01,  3.5733e-01,\n",
       "          2.2490e-01,  1.3277e-02,  4.0494e-02, -1.3025e-01, -1.3365e-01,\n",
       "          3.2034e-01,  2.6117e-01, -3.4705e-01,  1.7669e-01, -2.5380e-01,\n",
       "          3.0491e-02,  2.4185e-01,  2.4148e-01, -2.8340e-01,  7.3602e-02,\n",
       "         -3.1289e-01,  4.5428e-02,  5.6594e-01, -6.4136e-02,  1.3558e-01,\n",
       "          1.1851e-01, -2.3538e-01, -1.3218e-01,  1.9183e-01, -1.3600e-01,\n",
       "         -1.1494e+00,  3.6584e-01,  3.1123e-01,  2.8061e-01,  2.3955e-01,\n",
       "         -2.4946e-01,  3.0123e-01,  9.9572e-02, -2.3740e-01, -4.4925e-01,\n",
       "          5.2637e-02, -5.1481e-01, -6.5989e-01,  1.1719e-01, -6.3273e-02,\n",
       "         -1.1423e-01, -2.6833e-01, -1.9182e-02, -2.4028e-01, -4.4373e-02,\n",
       "         -1.7569e-01, -3.1760e-02,  7.9137e-02,  7.1695e-02, -6.7586e-02,\n",
       "          8.7838e-03,  2.0592e-01,  2.1970e-02,  3.6809e-01,  2.0450e-01,\n",
       "         -2.8241e-01,  2.8737e-01,  2.3896e-01,  3.5004e-03, -4.0584e-02,\n",
       "         -3.7527e-02, -3.1873e-01, -4.4533e-01, -1.8829e-02,  8.7480e-02,\n",
       "          3.9358e-02,  2.5384e-01, -1.7177e-01,  3.6704e-01,  1.1685e-01,\n",
       "          8.8151e-01, -1.8297e-01, -2.2382e-01, -2.5170e-01,  2.3097e-01,\n",
       "         -1.8420e-01, -1.2809e-01,  2.5144e-01, -1.3566e-01, -2.7711e-01,\n",
       "         -1.7238e-01, -2.2674e-01, -1.0894e-01, -2.2153e-01, -3.2150e-01,\n",
       "          5.1438e-02,  8.1830e-02,  4.4762e-01, -1.8171e-01,  1.7812e-01,\n",
       "          4.2392e-02,  2.0953e-01,  5.9237e-01, -1.5180e-01, -2.4848e-01,\n",
       "         -3.6314e-01, -2.7957e-01, -2.6763e-01, -4.0601e-01,  2.2221e-01,\n",
       "         -2.3289e-01,  2.8370e-02, -8.3566e-03, -6.9577e-02,  1.8851e-01,\n",
       "          5.0710e-01, -3.0316e-02, -9.0177e-02, -1.0820e-03, -2.5721e-01,\n",
       "         -4.3441e-01, -1.9286e-01,  2.4037e-01,  1.5816e-01,  2.6835e-01,\n",
       "          2.3048e-01,  1.8329e-01, -1.4023e-02,  4.2113e-01, -2.5815e-02,\n",
       "         -2.8211e-01, -4.1549e-02,  4.7246e-03,  4.9955e-02, -4.2047e-02,\n",
       "          2.4905e-01,  5.3173e-01, -4.2934e-01, -3.2588e-01,  1.0013e-01,\n",
       "         -3.6364e-01, -9.9431e-02,  6.2659e-01, -2.7112e-01, -2.1566e-01,\n",
       "         -1.5469e-01,  8.3550e-02, -3.6112e-01,  9.6514e-02, -1.7314e-01,\n",
       "          2.1588e-01,  1.5639e-01,  5.9367e-01,  6.6649e-01, -6.7588e-02,\n",
       "          1.5030e-01,  1.4506e-01,  2.5358e-01, -3.9685e-02, -2.3935e-01,\n",
       "          9.3357e-02,  4.7813e-01, -3.0064e-01, -3.7770e+00,  7.7552e-01,\n",
       "          4.0279e-01, -3.5019e-01,  3.8938e-02, -1.2376e-01, -1.1008e-01,\n",
       "         -4.8648e-01, -2.5933e-01,  1.7168e-01, -4.2279e-01, -5.5471e-01,\n",
       "          3.1611e-01, -1.1100e-01,  1.2557e-01, -4.5863e-01,  1.9956e-01,\n",
       "         -2.3371e-01,  1.4228e-01,  1.3801e-01, -1.9041e-01, -2.0123e-01,\n",
       "         -2.1891e-01,  1.7641e-01,  5.5051e-01,  4.2103e-01, -4.9933e-01,\n",
       "         -1.3517e-01,  2.4512e-01,  1.2218e-01,  1.2216e-01, -2.2440e-01,\n",
       "         -2.3644e-01, -4.1047e-01,  1.9044e-01,  7.0886e-02, -1.6605e-01,\n",
       "         -1.2517e-01, -1.0968e-02,  1.9421e-01, -2.5221e-01, -2.2930e-01,\n",
       "         -1.6755e-01,  4.9772e-02,  9.7385e-01,  1.3127e-01, -1.7879e-01,\n",
       "         -5.1492e-01,  4.2442e-02,  2.5898e-01,  4.4694e-01, -3.0948e-01,\n",
       "         -2.2084e-01,  2.9276e-01,  9.6880e-02, -8.7702e-03,  2.0275e-01,\n",
       "          3.3256e-02, -1.4174e-01, -4.4820e-02, -6.2446e-02, -4.6275e-01,\n",
       "         -1.0691e-01,  8.4085e-02, -9.6782e-03, -3.4852e-01, -3.5904e-01,\n",
       "         -2.2667e-03,  2.3287e-01,  8.2754e-03,  8.3930e-02,  3.9229e-01,\n",
       "         -3.9168e-01, -9.0533e-01, -3.2820e-01, -9.6770e-04,  6.3286e-01,\n",
       "         -2.0340e-01,  2.1092e-01, -5.2722e-02, -2.5226e-01, -1.9713e-01,\n",
       "          2.2695e-01, -1.2394e-01,  2.8051e-02, -3.8859e-01, -1.2037e-01,\n",
       "          3.0186e-01, -3.8589e-01, -6.7337e-01,  4.1308e-01,  3.9467e-01,\n",
       "          1.7403e-01, -5.0731e-02, -3.9395e-02,  6.4084e-02, -2.5928e-01,\n",
       "         -2.0895e-01, -6.6157e-03,  6.7344e-02, -5.3995e-02, -6.8231e-02,\n",
       "          3.9435e-01, -1.6228e-01, -5.9148e-02, -1.0987e-01, -2.3485e-01,\n",
       "          6.0764e-02, -5.2708e-01,  3.1985e-01,  1.5007e-01, -5.3241e-01,\n",
       "          7.4603e-01,  2.9624e-03,  7.0720e-02,  2.9006e-01,  5.8697e-01,\n",
       "          4.5578e-01,  7.8198e-02,  3.2700e-03, -2.5953e-01,  4.7365e-01,\n",
       "         -4.7452e-01, -3.1938e-01,  6.3678e-02, -1.2565e-01,  1.0425e-01,\n",
       "         -1.1837e-01,  8.1148e-02, -3.1782e-01,  8.7375e-02, -3.9548e-01,\n",
       "          1.2083e-01,  8.9850e-02,  3.7519e-01, -1.2269e-02,  2.2328e-01,\n",
       "         -1.1208e+00,  6.4219e-02,  3.6587e-01, -1.7193e-01,  2.0568e-01,\n",
       "         -1.2611e-02, -3.2089e-01, -2.5760e-01,  1.0754e-01,  3.6568e-02,\n",
       "         -6.1795e-02, -7.8660e-02, -8.2236e-02, -4.3350e-01, -9.8692e-04,\n",
       "          1.0287e-01, -5.2039e-01, -8.4610e-02,  3.9558e-01,  2.5404e-01,\n",
       "         -9.4515e-02, -5.6194e-01, -2.3692e-02,  9.7243e-02,  2.2519e-01,\n",
       "          3.9128e-01,  3.5818e-02, -9.8754e-01,  2.2243e-01, -4.9979e-01,\n",
       "         -2.7877e-01, -2.2256e-01,  7.1030e-01,  5.6814e-02, -2.4126e-01,\n",
       "          4.5316e-02,  9.8688e-02,  7.2636e-03,  3.4653e-01,  2.5113e-02,\n",
       "         -2.6737e-01, -2.0366e-01,  4.3638e-02, -3.6745e-01,  2.3696e-01,\n",
       "         -2.5555e-01, -2.9447e-01,  3.2046e-01, -4.0940e-02, -2.4763e-02,\n",
       "          8.6968e-02,  5.1339e-02, -1.8425e-04, -1.4893e-02,  3.2526e-01,\n",
       "         -3.8269e-02,  2.6786e-01, -3.5656e-01, -4.5695e-01,  1.3729e-01,\n",
       "          1.4438e-01,  2.3524e-02,  3.8044e-01,  1.5785e-01,  1.7076e-02,\n",
       "         -1.7419e-01, -9.5848e-02, -1.5767e-01, -3.8592e-01,  3.0318e-01,\n",
       "          1.5875e-01, -3.8609e-01,  4.4404e-01, -2.9244e-01,  2.0231e-02,\n",
       "         -6.4094e-01, -5.7448e-01,  1.5995e-01,  2.7726e-02,  4.6958e-01,\n",
       "          1.2975e-01, -2.8781e-01, -1.3774e-01, -3.7001e-01,  1.5315e-02,\n",
       "          1.5106e-01,  4.9227e-02, -6.1478e-01, -2.2820e-01,  1.9403e-01,\n",
       "          2.3295e-01,  3.1816e-02,  3.6159e-02, -2.0600e-02, -1.5040e-02,\n",
       "         -1.8070e-01,  2.5212e-01,  3.3567e-01,  1.7605e-01, -1.7763e-01,\n",
       "         -6.6003e-01, -1.5966e-01, -7.5785e-02, -9.2748e-02,  4.1193e-01,\n",
       "         -1.4701e-01,  1.8071e-01,  2.7727e-01,  2.2886e-01,  2.1412e-01,\n",
       "          4.0559e-01,  2.9488e-02,  1.5939e-01,  8.9484e-02,  1.7819e-02,\n",
       "          1.2578e-01,  2.1416e-01, -6.3731e-01, -1.3492e-01, -3.4915e-01,\n",
       "          3.6479e-02, -1.4420e-01,  2.2444e-01,  8.0618e-02, -4.5948e-01,\n",
       "         -2.5548e-01,  2.3308e-01,  4.8316e-01, -4.8303e-02,  1.3733e-01,\n",
       "          3.8448e-01,  1.9859e-01, -1.1588e-01,  1.9462e-01, -5.7137e-01,\n",
       "         -2.1804e-02,  1.8118e-02, -1.8648e-01,  3.2569e-01, -3.1400e-02,\n",
       "         -7.4852e-01, -2.8136e-01, -4.1346e-01, -4.3298e-01,  8.8853e-02,\n",
       "          8.0123e-02, -9.6356e-02, -1.0290e-01, -6.7089e-02, -1.8135e-02,\n",
       "          3.8983e-01, -2.2420e-01, -6.5782e-01,  1.6714e-01,  1.6647e-01,\n",
       "          2.2787e-01, -9.8913e-02, -4.9981e-02,  2.4047e-01,  5.1464e-01,\n",
       "          3.0415e-01,  1.9503e-01,  3.9066e-01, -7.7427e-02,  2.1399e-01,\n",
       "         -4.9991e-02,  3.7401e-01, -1.3171e-01,  2.5106e-01, -1.9302e-01,\n",
       "         -2.3373e-01, -1.2552e-01,  9.8667e-02, -2.5677e-01, -6.0451e-01,\n",
       "          2.7188e-01,  5.8789e-02, -4.7728e-01, -2.4809e-01,  1.0637e-01,\n",
       "         -2.4408e-01, -6.8313e-01,  1.5543e-01, -3.8480e-02, -1.0999e-01,\n",
       "          2.4612e-01,  3.1702e-01,  1.5008e-01,  4.7603e-01, -2.1330e-01,\n",
       "          2.5903e-02, -4.4135e-02,  1.8807e-01, -3.2210e-01,  5.7168e-02,\n",
       "         -2.6996e-01,  2.1716e-01, -2.0677e-01, -1.4930e-01,  6.6474e-02,\n",
       "         -3.5995e-01,  2.7575e-01, -3.3963e-01,  1.3209e-01, -1.0043e-01,\n",
       "         -2.8424e-02,  8.8633e-01,  2.6062e-01, -1.0798e-02, -1.2912e-01,\n",
       "         -2.6626e-02,  4.1478e-01,  3.0718e-01,  6.0709e-02,  9.1707e-02,\n",
       "         -4.0817e-02, -5.0389e-01,  6.9781e-01,  2.5277e-01,  2.0832e-01,\n",
       "         -7.7927e-02, -2.7423e-01,  3.0759e-01,  1.4393e-01, -1.9446e-01,\n",
       "          4.0682e-01, -5.2621e-01, -1.8164e-01,  1.4928e-01, -4.0263e-01,\n",
       "         -3.9829e-01, -8.1881e-02, -2.2226e-02,  3.0405e-01,  2.8618e-01,\n",
       "         -2.4212e-01, -4.5130e-01, -9.4954e-02,  4.1823e-01, -1.7606e-01,\n",
       "          2.2215e-01,  2.7882e-02, -1.7553e-01,  3.0287e-04, -2.4626e-01,\n",
       "         -4.1756e-01, -5.0924e-01, -3.4444e-01, -1.3423e-01, -2.6289e-02,\n",
       "         -1.0585e-01, -1.2218e-01, -5.4948e-01,  4.2556e-01, -3.3032e-01,\n",
       "          1.8397e-01, -2.3458e-02,  1.3004e-01, -4.7927e-01,  1.8001e-01,\n",
       "          5.1205e-01,  4.0620e-01, -4.9702e-02,  1.5907e-01, -3.3849e-01,\n",
       "         -1.8257e-02,  5.7775e-03, -3.4494e-01, -5.1503e-03,  1.3520e-01,\n",
       "         -2.2487e-02, -5.2574e-01,  4.5000e-01,  9.1079e-02, -7.8127e-02,\n",
       "         -8.1374e-01,  3.7877e-01, -1.3157e-02, -5.4255e-02,  2.0971e-01,\n",
       "          4.8571e-01, -1.9917e-01,  2.1274e-01, -1.1891e-02, -6.4185e-02,\n",
       "         -1.0941e-01,  1.4496e-01, -4.9473e-01,  4.1608e-01,  4.2309e-02,\n",
       "          5.6278e-02,  5.7971e-02,  7.4634e-02, -1.0295e-01,  3.8489e-02,\n",
       "          4.5559e-02,  2.2024e-01, -1.4470e-01, -3.0052e-01, -2.7554e-01,\n",
       "          5.3516e-01, -2.6329e-01,  1.9391e-01,  4.3121e-01,  1.2750e-02,\n",
       "          2.4978e-01,  8.1130e-02,  1.1838e-01, -4.8755e-02, -4.5545e-01,\n",
       "         -1.7653e-01,  2.3618e-01, -2.3790e-01, -1.9036e-01,  1.8762e-02,\n",
       "         -1.2124e-01, -4.1950e-01, -2.4885e-01, -1.0401e-01,  3.0579e-01,\n",
       "         -1.8370e-01, -8.9854e-02,  3.8368e-02]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\n"
     ]
    }
   ],
   "source": [
    "print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 after\n",
      "2 stealing\n",
      "3 money\n",
      "4 from\n",
      "5 the\n",
      "6 bank\n",
      "7 vault\n",
      "8 ,\n",
      "9 the\n",
      "10 bank\n",
      "11 robber\n",
      "12 was\n",
      "13 seen\n",
      "14 fishing\n",
      "15 on\n",
      "16 the\n",
      "17 mississippi\n",
      "18 river\n",
      "19 bank\n",
      "20 .\n",
      "21 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(tokenized_text):\n",
    "  print (i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First fifteen values of 'bank' as in 'bank robber':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1868, -1.5298, -1.3770,  1.0648,  3.1446,  1.4003, -4.2407,  1.3946,\n",
       "        -0.1170, -1.8777,  0.1091, -0.3862,  0.6744,  2.1924, -4.5306])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"First fifteen values of 'bank' as in 'bank robber':\")\n",
    "summed_last_4_layers[10][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First fifteen values of 'bank' as in 'bank vault':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 2.1319, -2.1413, -1.6260,  0.8638,  3.3173,  0.1796, -4.4853,  3.1215,\n",
       "        -0.9740, -3.1780,  0.1045, -1.5481,  0.4758,  1.1703, -4.4859])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"First fifteen values of 'bank' as in 'bank vault':\")\n",
    "summed_last_4_layers[6][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First fifteen values of 'bank' as in 'river bank':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1295, -1.4725, -0.7296, -0.0901,  2.4970,  0.5330,  0.9742,  5.1834,\n",
       "        -1.0692, -1.5941,  1.9261,  0.7119, -0.9809,  1.2127, -2.9812])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"First fifteen values of 'bank' as in 'river bank':\")\n",
    "summed_last_4_layers[19][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compare \"bank\" as in \"bank robber\" to \"bank\" as in \"river bank\"\n",
    "different_bank = cosine_similarity(summed_last_4_layers[10].reshape(1,-1), summed_last_4_layers[19].reshape(1,-1))[0][0]\n",
    "\n",
    "# Compare \"bank\" as in \"bank robber\" to \"bank\" as in \"bank vault\" \n",
    "same_bank = cosine_similarity(summed_last_4_layers[10].reshape(1,-1), summed_last_4_layers[6].reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20136365,  0.8558488 , -0.90959704, -2.0022335 ,  0.05285798,\n",
       "       -0.09729461, -0.12291355, -0.08967322, -0.5559663 ,  0.55344105,\n",
       "       -0.09683708,  1.7974255 , -0.23645914,  0.9595979 , -0.355906  ,\n",
       "       -0.47161824,  0.81053317,  0.16329156, -1.3595612 ,  0.6663488 ,\n",
       "        0.54851407, -0.17415449,  0.2818833 ,  2.2935798 ,  1.4775044 ,\n",
       "       -0.876686  , -0.4828207 ,  1.2497665 , -1.250145  ,  0.8328441 ,\n",
       "       -1.0026721 , -1.267679  ,  0.5168272 , -0.04681165,  2.0672045 ,\n",
       "       -1.1562798 ,  0.9741308 ,  1.2332971 , -0.72004116,  0.16166396,\n",
       "        0.11475471, -0.05980494, -0.5617358 , -0.12064459, -0.06153221,\n",
       "        0.7364133 ,  1.625066  , -0.06889956, -0.8148624 , -1.1105716 ,\n",
       "       -0.28389627, -0.6885798 , -1.0539786 , -1.0883272 , -0.5819933 ,\n",
       "        0.28235465, -1.4406666 ,  1.4301897 ,  2.377942  , -1.6349208 ,\n",
       "        0.16169724,  0.25153303,  0.7924581 ,  1.1010284 , -0.3240807 ,\n",
       "       -0.22770417,  0.04354021, -0.37510276, -0.10873371, -0.86253774,\n",
       "        1.3085144 , -0.560832  , -1.4053266 ,  0.21047425, -0.20414567,\n",
       "       -0.6439305 , -0.99213886,  0.71394026,  1.1691139 , -0.7380466 ,\n",
       "        0.2694706 ,  1.2944955 ,  0.0548632 ,  0.29287654, -0.31095618,\n",
       "       -1.0358887 , -2.3417025 ,  1.5146909 ,  1.841033  , -0.5946658 ,\n",
       "       -0.5037238 ,  0.88944674,  0.5921782 ,  0.2947924 ,  0.26320186,\n",
       "        0.11433683], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.3527856 ,  1.5364034 , -0.34534848, -2.6574855 ,  0.17459357,\n",
       "       -0.07838053,  0.16398804,  2.949361  ,  0.7446209 , -2.8426688 ,\n",
       "        1.01109   , -1.4075065 , -0.80491817,  3.8867738 , -2.4497879 ,\n",
       "       -0.676257  ,  0.1795485 , -3.1324651 , -2.3045454 , -1.9656184 ,\n",
       "        1.2784417 ,  1.3653405 ,  0.4712348 ,  3.6835637 ,  1.4607272 ,\n",
       "       -0.26173374,  2.2768283 ,  3.3023174 , -2.5614347 , -1.5722078 ,\n",
       "       -3.7269034 , -1.5898702 ,  0.1103521 , -1.7075908 ,  3.2840946 ,\n",
       "       -4.006767  ,  0.45580792,  1.9496741 ,  0.8073076 , -2.0288486 ,\n",
       "        0.75987005, -0.54913837, -0.28429893,  0.3500445 ,  3.6737561 ,\n",
       "        1.6106148 ,  4.5643983 ,  0.42886662, -2.7789893 , -2.2541978 ,\n",
       "       -0.08394778, -0.7164993 , -0.7259246 ,  0.19097483, -0.4519309 ,\n",
       "        1.3490716 , -3.535676  ,  4.051957  ,  4.832258  , -3.3579922 ,\n",
       "        0.2230306 , -1.102554  ,  0.10533589,  3.5841658 ,  0.09987053,\n",
       "        0.70994174, -1.8589908 , -0.17476669,  2.9334877 , -1.312393  ,\n",
       "        0.6472362 , -0.65662706, -3.944823  , -0.21976578, -0.7308988 ,\n",
       "       -0.7485542 ,  0.7326567 ,  0.5232996 ,  1.8165927 , -1.3752398 ,\n",
       "        0.8434597 ,  2.9556887 , -0.3675108 ,  0.26591533,  0.38084182,\n",
       "       -1.3532579 , -2.0897245 ,  3.7397246 ,  3.5523129 , -0.7498689 ,\n",
       "       -1.3470725 , -0.8912637 ,  0.6414315 ,  0.06821708, -1.5090156 ,\n",
       "       -2.5107431 ], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[9].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7249882 , -0.24712256,  1.3216904 , -6.458606  ,  0.5020842 ,\n",
       "        0.63012844, -0.27721125,  3.7578526 ,  0.6039228 , -1.9971237 ,\n",
       "        0.39006793, -0.94834006, -0.44606525, -0.23227745,  0.49765533,\n",
       "       -0.37558216,  0.676269  , -0.879135  , -1.7579178 ,  0.1229308 ,\n",
       "        2.5017128 ,  0.5192864 ,  3.0233808 ,  5.643265  ,  3.9918735 ,\n",
       "       -3.912091  ,  0.69894326,  1.448861  , -1.7716358 , -0.5042784 ,\n",
       "       -2.6361802 , -1.0682964 , -4.7989597 , -0.11987513,  4.414299  ,\n",
       "       -4.0782657 ,  0.7600807 ,  2.4989939 , -2.6806858 , -0.35546955,\n",
       "        1.7425576 ,  2.3621912 , -0.7879547 , -0.25962973,  2.8525693 ,\n",
       "       -0.9905433 ,  2.0743265 ,  2.7730978 , -0.49942034, -0.6372614 ,\n",
       "        0.32685396, -3.493502  , -2.041121  , -2.8379018 , -1.8471127 ,\n",
       "       -1.547224  , -2.6406364 ,  1.9618655 ,  4.1340623 , -2.9840367 ,\n",
       "        1.1072215 ,  2.7083545 ,  0.5886741 ,  3.8353302 ,  1.0379041 ,\n",
       "        2.2892525 , -0.6877442 , -0.7302381 ,  1.23956   , -0.23066059,\n",
       "        2.387715  , -1.1070719 , -1.6809474 ,  2.459916  , -1.8935829 ,\n",
       "       -2.507571  , -0.5800203 , -0.64931643,  0.8085823 , -0.61727077,\n",
       "       -1.3115335 ,  2.856708  ,  0.4541208 , -0.8246385 , -1.4660883 ,\n",
       "        1.2150028 , -3.2940712 ,  2.9073331 ,  2.9417086 ,  0.864735  ,\n",
       "       -0.9119632 ,  0.3572632 ,  1.4001241 , -1.7259928 , -0.18834072,\n",
       "       -2.4170604 ], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[18].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.0978775e-01,  1.5162129e+00,  8.6049581e-01, -1.5532432e+00,\n",
       "       -6.8119526e-01,  9.8694760e-01,  9.3608916e-01,  1.9538394e+00,\n",
       "       -1.4366362e+00, -1.9292169e+00,  5.7436848e-01,  2.7897605e-01,\n",
       "       -2.2740227e-01,  5.2807245e+00, -2.5897789e+00,  5.1210976e-01,\n",
       "       -4.6914852e-01, -3.4868803e+00, -1.8712564e+00, -4.0094495e-02,\n",
       "        2.2476783e+00,  1.5026965e+00,  8.0708194e-01,  3.0180011e+00,\n",
       "        1.8983470e+00, -5.1863074e-01,  5.0027832e-02,  4.0467367e+00,\n",
       "       -2.6064267e+00, -5.2322793e-01, -2.2480693e+00, -2.4013357e+00,\n",
       "        1.2991195e+00, -1.8650111e+00,  2.0911574e+00, -3.5860128e+00,\n",
       "        1.2236983e+00,  8.3517373e-01, -1.2338824e+00, -1.6384890e+00,\n",
       "        9.1354299e-01,  1.3220488e+00, -2.4393263e-01,  4.7999501e-02,\n",
       "        2.5791550e+00,  1.5372406e+00,  3.7844346e+00,  1.0160033e+00,\n",
       "       -1.1462696e+00, -2.4606314e+00,  3.0954963e-01, -8.7353891e-01,\n",
       "        5.9076715e-01, -1.5679519e+00, -1.4517182e+00,  3.6638421e-01,\n",
       "       -2.6589270e+00,  5.3274221e+00,  3.1949615e+00, -3.0085502e+00,\n",
       "       -5.1919496e-01,  4.7384262e-02, -1.3362467e+00,  4.0326738e+00,\n",
       "        1.3414129e+00, -4.2011589e-03, -1.7220041e+00, -6.1565000e-01,\n",
       "        2.3041842e+00, -1.4182048e+00, -1.0278008e+00, -1.3662972e+00,\n",
       "       -3.7422564e+00, -1.0553997e+00,  6.9152761e-01, -5.0861847e-01,\n",
       "       -1.3845307e-01,  9.4818503e-01,  1.1043849e+00, -2.9138286e+00,\n",
       "       -9.8208952e-01,  2.1048279e+00, -1.6792818e+00, -3.3691704e-01,\n",
       "       -8.6217624e-01,  6.8644440e-01, -2.2029395e+00,  3.8371930e+00,\n",
       "        3.4039447e+00,  2.5185299e-01, -2.0622177e+00, -6.4572144e-01,\n",
       "        8.7134540e-01,  1.0283592e+00, -1.4471881e+00,  3.5158169e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[5].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compare \"bank\" as in \"bank robber\" to \"bank\" as in \"river bank\"\n",
    "different_bank = cosine_similarity(doc[9].vector.reshape(-1, 1), doc[18].vector.reshape(-1, 1))[0][0]\n",
    "\n",
    "# Compare \"bank\" as in \"bank robber\" to \"bank\" as in \"bank vault\" \n",
    "same_bank = cosine_similarity(doc[9].vector.reshape(-1, 1), doc[5].vector.reshape(-1, 1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1., -1., ...,  1.,  1.,  1.],\n",
       "       [ 1., -1.,  1., ..., -1., -1., -1.],\n",
       "       [-1.,  1., -1., ...,  1.,  1.,  1.],\n",
       "       ...,\n",
       "       [ 1., -1.,  1., ..., -1., -1., -1.],\n",
       "       [-1.,  1., -1., ...,  1.,  1.,  1.],\n",
       "       [-1.,  1., -1., ...,  1.,  1.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(doc[9].vector.reshape(-1, 1), doc[18].vector.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1., -1., ..., -1.,  1., -1.],\n",
       "       [-1.,  1.,  1., ...,  1., -1.,  1.],\n",
       "       [ 1., -1., -1., ..., -1.,  1., -1.],\n",
       "       ...,\n",
       "       [-1.,  1.,  1., ...,  1., -1.,  1.],\n",
       "       [ 1., -1., -1., ..., -1.,  1., -1.],\n",
       "       [ 1., -1., -1., ..., -1.,  1., -1.]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " cosine_similarity(doc[9].vector.reshape(-1, 1), doc[5].vector.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bank"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3527856 ],\n",
       "       [ 1.5364034 ],\n",
       "       [-0.34534848],\n",
       "       [-2.6574855 ],\n",
       "       [ 0.17459357],\n",
       "       [-0.07838053],\n",
       "       [ 0.16398804],\n",
       "       [ 2.949361  ],\n",
       "       [ 0.7446209 ],\n",
       "       [-2.8426688 ],\n",
       "       [ 1.01109   ],\n",
       "       [-1.4075065 ],\n",
       "       [-0.80491817],\n",
       "       [ 3.8867738 ],\n",
       "       [-2.4497879 ],\n",
       "       [-0.676257  ],\n",
       "       [ 0.1795485 ],\n",
       "       [-3.1324651 ],\n",
       "       [-2.3045454 ],\n",
       "       [-1.9656184 ],\n",
       "       [ 1.2784417 ],\n",
       "       [ 1.3653405 ],\n",
       "       [ 0.4712348 ],\n",
       "       [ 3.6835637 ],\n",
       "       [ 1.4607272 ],\n",
       "       [-0.26173374],\n",
       "       [ 2.2768283 ],\n",
       "       [ 3.3023174 ],\n",
       "       [-2.5614347 ],\n",
       "       [-1.5722078 ],\n",
       "       [-3.7269034 ],\n",
       "       [-1.5898702 ],\n",
       "       [ 0.1103521 ],\n",
       "       [-1.7075908 ],\n",
       "       [ 3.2840946 ],\n",
       "       [-4.006767  ],\n",
       "       [ 0.45580792],\n",
       "       [ 1.9496741 ],\n",
       "       [ 0.8073076 ],\n",
       "       [-2.0288486 ],\n",
       "       [ 0.75987005],\n",
       "       [-0.54913837],\n",
       "       [-0.28429893],\n",
       "       [ 0.3500445 ],\n",
       "       [ 3.6737561 ],\n",
       "       [ 1.6106148 ],\n",
       "       [ 4.5643983 ],\n",
       "       [ 0.42886662],\n",
       "       [-2.7789893 ],\n",
       "       [-2.2541978 ],\n",
       "       [-0.08394778],\n",
       "       [-0.7164993 ],\n",
       "       [-0.7259246 ],\n",
       "       [ 0.19097483],\n",
       "       [-0.4519309 ],\n",
       "       [ 1.3490716 ],\n",
       "       [-3.535676  ],\n",
       "       [ 4.051957  ],\n",
       "       [ 4.832258  ],\n",
       "       [-3.3579922 ],\n",
       "       [ 0.2230306 ],\n",
       "       [-1.102554  ],\n",
       "       [ 0.10533589],\n",
       "       [ 3.5841658 ],\n",
       "       [ 0.09987053],\n",
       "       [ 0.70994174],\n",
       "       [-1.8589908 ],\n",
       "       [-0.17476669],\n",
       "       [ 2.9334877 ],\n",
       "       [-1.312393  ],\n",
       "       [ 0.6472362 ],\n",
       "       [-0.65662706],\n",
       "       [-3.944823  ],\n",
       "       [-0.21976578],\n",
       "       [-0.7308988 ],\n",
       "       [-0.7485542 ],\n",
       "       [ 0.7326567 ],\n",
       "       [ 0.5232996 ],\n",
       "       [ 1.8165927 ],\n",
       "       [-1.3752398 ],\n",
       "       [ 0.8434597 ],\n",
       "       [ 2.9556887 ],\n",
       "       [-0.3675108 ],\n",
       "       [ 0.26591533],\n",
       "       [ 0.38084182],\n",
       "       [-1.3532579 ],\n",
       "       [-2.0897245 ],\n",
       "       [ 3.7397246 ],\n",
       "       [ 3.5523129 ],\n",
       "       [-0.7498689 ],\n",
       "       [-1.3470725 ],\n",
       "       [-0.8912637 ],\n",
       "       [ 0.6414315 ],\n",
       "       [ 0.06821708],\n",
       "       [-1.5090156 ],\n",
       "       [-2.5107431 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[9].vector.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7249882 ],\n",
       "       [-0.24712256],\n",
       "       [ 1.3216904 ],\n",
       "       [-6.458606  ],\n",
       "       [ 0.5020842 ],\n",
       "       [ 0.63012844],\n",
       "       [-0.27721125],\n",
       "       [ 3.7578526 ],\n",
       "       [ 0.6039228 ],\n",
       "       [-1.9971237 ],\n",
       "       [ 0.39006793],\n",
       "       [-0.94834006],\n",
       "       [-0.44606525],\n",
       "       [-0.23227745],\n",
       "       [ 0.49765533],\n",
       "       [-0.37558216],\n",
       "       [ 0.676269  ],\n",
       "       [-0.879135  ],\n",
       "       [-1.7579178 ],\n",
       "       [ 0.1229308 ],\n",
       "       [ 2.5017128 ],\n",
       "       [ 0.5192864 ],\n",
       "       [ 3.0233808 ],\n",
       "       [ 5.643265  ],\n",
       "       [ 3.9918735 ],\n",
       "       [-3.912091  ],\n",
       "       [ 0.69894326],\n",
       "       [ 1.448861  ],\n",
       "       [-1.7716358 ],\n",
       "       [-0.5042784 ],\n",
       "       [-2.6361802 ],\n",
       "       [-1.0682964 ],\n",
       "       [-4.7989597 ],\n",
       "       [-0.11987513],\n",
       "       [ 4.414299  ],\n",
       "       [-4.0782657 ],\n",
       "       [ 0.7600807 ],\n",
       "       [ 2.4989939 ],\n",
       "       [-2.6806858 ],\n",
       "       [-0.35546955],\n",
       "       [ 1.7425576 ],\n",
       "       [ 2.3621912 ],\n",
       "       [-0.7879547 ],\n",
       "       [-0.25962973],\n",
       "       [ 2.8525693 ],\n",
       "       [-0.9905433 ],\n",
       "       [ 2.0743265 ],\n",
       "       [ 2.7730978 ],\n",
       "       [-0.49942034],\n",
       "       [-0.6372614 ],\n",
       "       [ 0.32685396],\n",
       "       [-3.493502  ],\n",
       "       [-2.041121  ],\n",
       "       [-2.8379018 ],\n",
       "       [-1.8471127 ],\n",
       "       [-1.547224  ],\n",
       "       [-2.6406364 ],\n",
       "       [ 1.9618655 ],\n",
       "       [ 4.1340623 ],\n",
       "       [-2.9840367 ],\n",
       "       [ 1.1072215 ],\n",
       "       [ 2.7083545 ],\n",
       "       [ 0.5886741 ],\n",
       "       [ 3.8353302 ],\n",
       "       [ 1.0379041 ],\n",
       "       [ 2.2892525 ],\n",
       "       [-0.6877442 ],\n",
       "       [-0.7302381 ],\n",
       "       [ 1.23956   ],\n",
       "       [-0.23066059],\n",
       "       [ 2.387715  ],\n",
       "       [-1.1070719 ],\n",
       "       [-1.6809474 ],\n",
       "       [ 2.459916  ],\n",
       "       [-1.8935829 ],\n",
       "       [-2.507571  ],\n",
       "       [-0.5800203 ],\n",
       "       [-0.64931643],\n",
       "       [ 0.8085823 ],\n",
       "       [-0.61727077],\n",
       "       [-1.3115335 ],\n",
       "       [ 2.856708  ],\n",
       "       [ 0.4541208 ],\n",
       "       [-0.8246385 ],\n",
       "       [-1.4660883 ],\n",
       "       [ 1.2150028 ],\n",
       "       [-3.2940712 ],\n",
       "       [ 2.9073331 ],\n",
       "       [ 2.9417086 ],\n",
       "       [ 0.864735  ],\n",
       "       [-0.9119632 ],\n",
       "       [ 0.3572632 ],\n",
       "       [ 1.4001241 ],\n",
       "       [-1.7259928 ],\n",
       "       [-0.18834072],\n",
       "       [-2.4170604 ]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[18].vector.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
